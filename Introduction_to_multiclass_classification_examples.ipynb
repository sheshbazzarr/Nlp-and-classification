{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Examples: Introduction to multiclass classification\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll delve into the fundamentals of multiclass classification, address class imbalance, and apply logistic regression to the MBTI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "- Understand and address class imbalance in the context of multiclass classification.\n",
    "- Apply logistic regression techniques for multiclass classification problems.\n",
    "- Gain practical experience with logistic regression on the MBTI dataset, navigating through its unique challenges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3297e8",
   "metadata": {},
   "source": [
    "## Dealing with class imbalance\n",
    "\n",
    "In this train, we will be exploring a phenomenon known as **class imbalance** and learning how to deal with it. Class imbalance occurs when the number of observations across different class labels is unevenly distributed. In training our classification model, it is preferable for all classes to have a relatively even split of observations. However, in the wild, classification datasets often come with unevenly distributed observations, with one class or set of classes having way more observations than others.\n",
    "\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/class-imbalance.png?raw=true\" width=80% alt=\"class imbalance img\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7822a60",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "As it turns out, some clever scientists have come up with various ways to address this so-called class imbalance problem. Here we will discuss two variants of the most common method available: **resampling**. Put simply, resampling methods involve modifying the number of observations in each class as follows:\n",
    "\n",
    "- **Downsampling** – taking a random subset of the majority class small enough to match the number of observations in the minority class.\n",
    "\n",
    "- **Upsampling** – taking repeated random samples from the minority class until we have as many observations as the  majority class. This grows the size of the minority class by effectively duplicating observations at random.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/upsample-downsample.png?raw=true\" width=80% alt=\"class imbalance img\">\n",
    "\n",
    "Let's use an example to demonstrate how these work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be184e",
   "metadata": {},
   "source": [
    "### Example 1: Resampling the email spam classification dataset\n",
    "\n",
    "One famous dataset for email spam detection is the [Spambase dataset](https://archive.ics.uci.edu/ml/datasets/spambase), which contains a set of features indicating whether or not a particular email is spam. We chose this dataset because of its inherent class imbalance. As you can imagine, the average person receives way more non-spam email than spam email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Set the path to the CA certificates bundle\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9555b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load a modified version of the Spambase dataset\n",
    "df = pd.read_csv('https://github.com/Explore-AI/Public-Data/blob/master/Data/classification_sprint/unbalanced_email_spam_data.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace5340",
   "metadata": {},
   "source": [
    "Let's do a quick analysis of the distribution of observations across our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate minority and majority classes\n",
    "not_spam = df[df['spam']==0]\n",
    "spam = df[df['spam']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possible labels\n",
    "labels = df['spam'].unique()\n",
    "heights = [len(spam),len(not_spam)]\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['spam','not spam'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b425f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of non-spam emails in the dataset \n",
    "len(not_spam)/(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39100ac",
   "metadata": {},
   "source": [
    "As you can see, our two classes are imbalanced. To put this in perspective as to why this is such an issue, say we had a model that always predicts that a given email is not spam (clearly a really bad model!). Such a model would achieve an accuracy of 87%! This is why (as explained in previous trains) class imbalance can be a serious problem if left unchecked. \n",
    "\n",
    "Let's use resampling techniques to fix this. Notice that we are keeping our features and labels together for the time being so that they get sampled together (otherwise we risk mixing labels and observations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, we start by importing our modules\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f5a7f",
   "metadata": {},
   "source": [
    "#### Example 1.1: Approach 1 – Downsampling the majority class\n",
    "\n",
    "Since the `not_spam` class has so many observations, we can reduce its size by taking a small random subset of observations to match the size of the `spam` class. Because this approach reduces the overall size of the dataset, it makes sense to use it only in cases where we have a big collection of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample majority\n",
    "not_spam_downsampled = resample(not_spam,\n",
    "                          replace=False, # sample without replacement (no need to duplicate observations)\n",
    "                          n_samples=len(spam), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled = pd.concat([not_spam_downsampled, spam])\n",
    "\n",
    "# Check new class counts\n",
    "downsampled['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdeb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_heights = [len(downsampled[downsampled['spam']==0]),len(downsampled[downsampled['spam']==1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = df['spam'].unique()\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.bar(labels,downsampled_heights,color='orange')\n",
    "plt.xticks(labels,['spam','not spam'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.legend(['original','resampled'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd62fe",
   "metadata": {},
   "source": [
    "#### Example 1.2: Approach 2 – Upsampling the minority class\n",
    "\n",
    "Here, we simply make random copies of observations in the minority class until we match the size of the majority class. Using this approach means we end up with more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority\n",
    "spam_upsampled = resample(spam,\n",
    "                          replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                          n_samples=len(not_spam), # match number in minority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# Combine upsampled minority class with majority class\n",
    "upsampled = pd.concat([spam_upsampled, not_spam])\n",
    "\n",
    "# Check new class counts\n",
    "upsampled['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_heights = [len(upsampled[upsampled['spam']==0]),len(upsampled[upsampled['spam']==1])]\n",
    "\n",
    "# Get all possible labels\n",
    "labels = df['spam'].unique()\n",
    "plt.bar(labels,upsampled_heights,color='orange')\n",
    "plt.bar(labels,heights,color='grey')\n",
    "plt.xticks(labels,['spam','not spam'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.legend(['resampled','original'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5de1d3",
   "metadata": {},
   "source": [
    "#### Example 1.3: Approach 3 – Best of both (upsample minority class and downsample majority class)\n",
    "\n",
    "As you may have guessed, this approach involves performing both kinds of resampling techniques. \n",
    "\n",
    "#### Exercise: See if you can implement this technique by following these steps:\n",
    "\n",
    "1. Establish a **class size** (i.e. the number of observations we want in each class). For this approach to work, the **class size** has to be a value between the size of the majority class and the size of the minority class. A good heuristic to use is to **set the class size to be half the size of the majority class**.\n",
    "\n",
    "2. Downsample the majority class to be as small as the **class size**.\n",
    "\n",
    "3. Upsample the minority class to be as big as the **class size**.\n",
    "\n",
    "4. *Et voila!* You should now have evenly distributed observations that you can throw at any classification model you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b52e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your awesome code here :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18ceae",
   "metadata": {},
   "source": [
    "### Example 2: Logistic regression on the MBTI dataset\n",
    "\n",
    "Another famous dataset is the MBTI dataset. In this train, we will fit a logistic regression model to the MBTI dataset and attempt to predict personality types given some text.\n",
    "\n",
    "As always, we start by loading some dependencies and preprocessing our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7736957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Customise our plotting settings\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c0110",
   "metadata": {},
   "source": [
    "#### Example 2.1: Getting and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a187e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MBTI data\n",
    "mbti = pd.read_csv('https://github.com/Explore-AI/Public-Data/blob/master/Data/classification_sprint/mbti.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58af8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mbti = mbti[['type', 'post']].groupby('type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posts by personality types\n",
    "sum_mbti.sort_values('post', ascending=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba30d7",
   "metadata": {},
   "source": [
    "At this point, we can see the imbalance creeping in. The introverted types have way more posts than the extroverted types. But before we fix this using some resampling kung fu, let's first vectorise our data. \n",
    "\n",
    "*Can you come up with reasons why it makes sense to vectorise before resampling?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd45d20",
   "metadata": {},
   "source": [
    "#### Example 2.3: Transforming text into numbers\n",
    "\n",
    "**1. Features**\n",
    "\n",
    "Before we can feed our data into our machine learning model, we need to first transform the text into numbers. One common method well suited for this task is count vectorisation. We can apply this method using Sklearn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the count vectoriser with its default hyperparameters\n",
    "vect = CountVectorizer()\n",
    "X_count = vect.fit_transform(mbti['post'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace268a",
   "metadata": {},
   "source": [
    "There should already be alarm bells sounding here.  We have more than 315,000 rows, which is enough data for this algorithm to run effectively.  We, however,  have almost 122,000 features – a lot of which correspond to words that only appear once (see if you can verify this on your own).  \n",
    "\n",
    "For this train, we will be using the top 20 words that appear most often, to make our model easier to train. Don't worry too much about this step. We will cover hyperparameter tuning in future trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_20 = CountVectorizer(lowercase=True, stop_words='english', max_features=20,analyzer='word', ngram_range=(1, 3))\n",
    "X_count = vect_20.fit_transform(mbti['post'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this line to see feature names\n",
    "vect_20.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of our new predictive variables\n",
    "X_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff5b3d",
   "metadata": {},
   "source": [
    "**2. Response variable**\n",
    "\n",
    "Since our response consists of text categories, we need to somehow also convert to numerical values. Luckily for us, Sklearn has just the thing. Introducing the [Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Unlike the `pd.get_dummies` method which creates a new column for every category it encounters, the LabelEncoder replaces each category with a number. The first category encountered will be replaced with a 0, the next one with a 1, the next with a 2, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b083213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Fit label encoder and return encoded labels\n",
    "y = le.fit_transform(mbti['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966c26d",
   "metadata": {},
   "source": [
    "And just like that, we have transformed our labels into a range of values between 0 and 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label encoder types to use for lookup \n",
    "type_labels = list(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c39a51",
   "metadata": {},
   "source": [
    "#### Example 2.4: Training the logistic regression model on standard MBTI data\n",
    "\n",
    "Finally, our data are cleaned and processed, and we are now in a position to train a logistic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0996cc9",
   "metadata": {},
   "source": [
    "**Setting up the train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0996151",
   "metadata": {},
   "source": [
    "**Training the model**\n",
    "\n",
    "Sklearn's logistic regression model has the capacity to accommodate multiple classes, even though logistic regression is a binary classification model. One way it does this is through a [One vs Rest](https://chrisalbon.com/machine_learning/logistic_regression/one-vs-rest_logistic_regression/) scheme (i.e. one class vs the rest of the classes). This means that we split the multiclass classification problem into multiple binary classification problems as follows:\n",
    "\n",
    "- Class 1 and not Class 1\n",
    "- Class 2 and not Class 2\n",
    "- Class 3 and not Class 3\n",
    "-   ...          ...\n",
    "- Class n and not Class n\n",
    "\n",
    "We then train a logistic regression model for each of these. At test time, we run the same test data through all the models and take the prediction of the logistic regression model with the highest probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here 'ovr' indicates that we have selected our One-vs-Rest strategy. \n",
    "logreg = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537df30",
   "metadata": {},
   "source": [
    "**Note:** The cell below may take a while to train depending on the number of features you have (up to five minutes for slower computers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d203eab",
   "metadata": {},
   "source": [
    "#### Example 2.5: Checking outcomes on the testing set\n",
    "\n",
    "We now investigate the performance of our newly trained models on the test set of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be30c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_test, target_names=type_labels))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb7831",
   "metadata": {},
   "source": [
    "As you can see, this gives us an overall accuracy of 21% (this is the percentage of times we predict the correct class in the data). We also get a weighed F1 score of 0.07. Now, besides these numbers, there are a lot of other issues here – the biggest one being that our model never predicts some of the classes. \n",
    "\n",
    "That said, the model is not completely useless since it does slightly better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab946b1b",
   "metadata": {},
   "source": [
    "### Example 3: Training the logistic regression model on balanced MBTI data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71dcbe",
   "metadata": {},
   "source": [
    "We now try to improve our model performance by rebalancing our data. Before we do so, let's first have a look at the current distribution of classes again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = [len(y[y == label]) for label in range(len(type_labels))]\n",
    "bars = pd.DataFrame(zip(heights,le.transform(type_labels).T, type_labels), columns=['heights','labels','names'])\n",
    "bars = bars.sort_values(by='heights',ascending=True)\n",
    "\n",
    "plt.bar(range(len(bars)),bars['heights'],color='grey')\n",
    "plt.xticks(range(len(bars)),bars['names'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d7237",
   "metadata": {},
   "source": [
    "This time we have way more than two classes. This makes our resampling a bit complicated, but as before, let's decide on a **class size**. Looking at the bars above, we want to bring the minority classes up as much as possible, but at the same time, we don't want to lose too much data from the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96904472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a class size of roughly half the size of the largest size\n",
    "class_size = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f5643",
   "metadata": {},
   "source": [
    "Next, we have to upsample anything that has samples fewer than the class size and downsample anything with samples more than the class size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98078e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before resampling, let's stitch our features and labels together\n",
    "data = np.concatenate([X, y[:,np.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_label_df = bars.set_index('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_classes = []\n",
    "\n",
    "# For each label\n",
    "for label in range(len(type_labels)):\n",
    "    # Get num. of observations from this class\n",
    "    label_size = bar_label_df.loc[label]['heights']\n",
    "    \n",
    "    # If label_size < class size the upsample, else downsample\n",
    "    if label_size < class_size:\n",
    "        # Upsample\n",
    "        label_data = data[data[:,-1] == label]\n",
    "        label_resampled = resample(label_data,\n",
    "                                  replace=True, # sample with replacement (we need to duplicate observations)\n",
    "                                  n_samples=class_size, # number of desired samples\n",
    "                                  random_state=27) # reproducible results\n",
    "    else:\n",
    "        # Downsample\n",
    "        label_data = data[data[:,-1] == label]\n",
    "        label_resampled = resample(label_data,\n",
    "                                  replace=False, # sample without replacement (no need for duplicate observations)\n",
    "                                  n_samples=class_size, # number of desired samples\n",
    "                                  random_state=27) # reproducible results\n",
    "        \n",
    "    resampled_classes.append(label_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b746de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = np.concatenate(resampled_classes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c07018",
   "metadata": {},
   "source": [
    "Split resampled data into X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled = resampled_data[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled = resampled_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c0e90",
   "metadata": {},
   "source": [
    "Now let's view the after image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = [len(y_resampled[y_resampled == label]) for label in range(len(type_labels))]\n",
    "bars_resampled = pd.DataFrame(zip(heights,le.transform(type_labels).T, type_labels), columns=['heights','labels','names'])\n",
    "bars_resampled = bars_resampled.sort_values(by='heights',ascending=True)\n",
    "\n",
    "plt.bar(range(len(bars)),bars['heights'],color='grey')\n",
    "plt.bar(range(len(bars_resampled)),bars_resampled['heights'],color='orange')\n",
    "plt.xticks(range(len(bars)),bars['names'])\n",
    "plt.ylabel(\"# of observations\")\n",
    "plt.legend(['original','resampled'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d230325",
   "metadata": {},
   "source": [
    "Now, after taking a moment to appreciate what we just did, let's keep in mind that we don't always have to resample such that all classes end up equal.\n",
    "\n",
    "**Train test split with balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1081e7c",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd184f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the logistic regression model on our rebalanced data\n",
    "logreg = LogisticRegression(multi_class='ovr')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781a8e",
   "metadata": {},
   "source": [
    "**Checking outcomes on the testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test, y_pred_test, target_names=type_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b4c1e",
   "metadata": {},
   "source": [
    "The resulting model still has poor accuracy. But at least this time our model is better at predicting more of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67d668",
   "metadata": {},
   "source": [
    "## Where to from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d258e799",
   "metadata": {},
   "source": [
    "Turns out our first model is not very good!  Don't be discouraged as our first attempt usually never is! Generally, there are a couple of methods to try and improve our model:\n",
    "* Improve the data and feature set.\n",
    "* Try a different model.\n",
    "* Fine-tune the algorithm parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d9f00",
   "metadata": {},
   "source": [
    "In your own time, try and use the above suggestions to make this model better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51f451",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "In this train, we learned how to deal with class imbalance and the different resampling techniques that can be applied to imbalanced data. We also applied the use of a logistic regression model on unbalanced and balanced data evaluating the outcome of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
